---
categories: machine learning updates
date: 2023-10-03 12:32:14 -0500
layout: post
title: 'Lewis Tunstall: Hugging Face, SetFit and Reinforcement Learning | Learning
  from Machine Learning #6'
youtubeID: XNFqFT-DZwo
---
Watch on [YouTube](https://www.youtube.com/watch?v=XNFqFT-DZwo):
<iframe width="560" height="315" src="https://www.youtube.com/embed/XNFqFT-DZwo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

<p>This episode features Lewis Tunstall, machine learning engineer at Hugging Face and author of the best selling book Natural Language Processing with Transformers. He currently focuses on one of the hottest topic in NLP right now reinforcement learning from human feedback (RLHF). Lewis holds a PhD in quantum physics and his research has taken him around the world and into some of the most impactful projects including the Large Hadron Collider, the world's largest and most powerful particle accelerator. Lewis shares his unique story from Quantum Physicist to Data Scientist to Machine Learning Engineer. </p><p><em>Resources to learn more about Lewis Tunstall</em></p><ul><li><a href="https://www.linkedin.com/in/lewis-tunstall/">https://www.linkedin.com/in/lewis-tunstall/</a></li><li><a href="https://github.com/lewtun">https://github.com/lewtun</a></li></ul><p><em>References from the Episode</em></p><ul><li><a href="https://www.fast.ai/">https://www.fast.ai/</a></li><li><a href="https://jeremy.fast.ai/">https://jeremy.fast.ai/</a></li><li><a href="https://github.com/huggingface/setfit">SetFit</a> - <a href="https://arxiv.org/abs/2209.11055">https://arxiv.org/abs/2209.11055</a></li><li><a href="https://arxiv.org/abs/1707.06347">Proximal Policy Optimization</a></li><li><a href="https://openai.com/research/instruction-following">InstructGPT</a></li><li><a href="https://arxiv.org/abs/2109.14076">RAFT Benchmark</a></li><li><a href="https://openreview.net/pdf?id=wCFB37bzud4">Bidirectional Language Models are Also Few-Shot Learners</a></li><li><a href="https://youtu.be/jOj4d3JNBDU?si=JAhQdeotELxcX5F9">Nils Reimers - Sentence Transformers</a></li><li><a href="http://jalammar.github.io/illustrated-transformer/">Jay Alammar - Illustrated Transformer</a></li><li><a href="http://nlp.seas.harvard.edu/annotated-transformer/">Annotated Transformer</a></li><li>Moshe Wasserblat, Intel, NLP, Research Manager</li><li>Leandro von Werra, Co-Author of NLP with Transformers, Hugging Face Researcher</li><li>LLMSys - <a href="https://lmsys.org/">https://lmsys.org/</a></li><li>LoRA - Low-Rank Adaptation of Large Language Models</li></ul><p></p><p>Resources to learn more about Learning from Machine Learning</p><ul><li><a href="https://www.linkedin.com/company/learning-from-machine-learning">https://www.linkedin.com/company/learning-from-machine-learning</a></li><li><a href="https://mindfulmachines.substack.com/">https://mindfulmachines.substack.com/</a></li><li><a href="https://www.linkedin.com/in/sethplevine/">https://www.linkedin.com/in/sethplevine/</a></li><li><a href="https://medium.com/@levine.seth.p">https://medium.com/@levine.seth.p</a></li></ul>

<a href="https://podcasts.apple.com/us/podcast/learning-from-machine-learning/id1663925230?itsct=podcast_box_badge&amp;itscg=30200&amp;ls=1" style="display: inline-block; overflow: hidden; border-radius: 13px; width: 250px; height: 83px;"><img src="https://tools.applemediaservices.com/api/badges/listen-on-apple-podcasts/badge/en-us?size=250x83&amp;releaseDate=1673288700" alt="Listen on Apple Podcasts" style="border-radius: 13px; width: 250px; height: 83px;"></a>

Read more on [Substack](https://mindfulmachines.substack.com/p/lewis-tunstall-hugging-face-setfit)